---
title: "Análisis exploratorio"
author: "Majo Gil"
format: html
editor: visual
---

# Hoja de trabajo 3

```{r include=FALSE}

library(psych)
library(dplyr)
library(ggplot2)
library(reshape2)
library(psych)
library(corrplot)
library(RColorBrewer)
library(nortest)
library(lmtest)
library(jtools)

pricesTrain <- read.csv("train.csv")
```

## Análisis Exploratorio

```{r}

View(pricesTrain)
nrow(pricesTrain) 
ncol(pricesTrain) 
str(pricesTrain)
```

### Variables Categóricas:

-   Id

-   MSSubClass

-   MSZoning

-   Street

-   Alley

-   LotShape

-   LandContour

-   Utilities

-   LotConfig

-   LandSlope

-   Neighborhood

-   Condition 1

-   Condition 2

-   BldgType

-   HouseStyle

-   OverallQual

-   OverallCond

-   RoofStyle

-   RoofMatl

-   Exterior1st

-   Exterior2nd

-   MasVnrType

-   ExterQual

-   ExterCond

-   Foundation

-   BsmtQual

-   BsmtCond

-   BsmtExposure

-   BsmtFinType1

-   BsmtFinSF1

-   BsmtFinType2

-   Heating

-   HeatingQC

-   CentralAir

-   Electrical

-   Functional

-   FireplaceQu

-   GarageType

-   GarageFinish

-   GarageQual

-   GarageCcond

-   PavedDrive

-   PoolQC

-   Fence

-   MiscFeature

-   SaleType

-   SaleCondition

### Variables Cuantitativas

-   LotFrontage

-   LotArea

-   YearBuilt

-   YearRemodAdd

-   MasVnrArea

-   BsmtFinSF1

-   BsmtFinSF2

-   BsmtUnfSF

-   TotalBsmtSF

-   1stFlrSF

-   2ndFlrSF

-   LowQualFinSF

-   GrLivArea

-   BsmtFullBath

-   BsmtHalfBath

-   FullBath

-   HalfBath

-   Bedroom

-   Kitchen

-   TotRmsAbvGrd

-   Fireplaces

-   FireplaceQu

-   GarafeYrBlt

-   GarageCars

-   GarageArea

-   WoodDeckSF

-   OpenPorchSF

-   EnclosedPorch

-   3SsnPorch

-   ScreenPorch

-   PoolArea

-   MiscVal

-   MoSold

-   YrSold

### Eliminación de variables

A continuación se eliminarán las variables que se consideran innecesarias para el modelo

#### Gráfica de correlación de las variables

```{r}
# Graficar cada variable
#set.seed(100)
# Eliminar cualitativas
pricesTrainGraph <- pricesTrain %>% select(-c(Id,MSSubClass, MSZoning, Street, Alley, LotShape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, OverallQual, OverallCond, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, Heating, HeatingQC, CentralAir, Electrical, Functional, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PavedDrive, PoolQC, Fence, MiscFeature, SaleType, SaleCondition, KitchenQual))

# pairs(pricesTrainGraph)
# plot(pricesTrainGraph)

corPlot(pricesTrainGraph) # Correlación de todas las variables numéricas


cor(pricesTrainGraph[ , colnames(pricesTrainGraph) != "SalePrice"], pricesTrainGraph$SalePrice)


mcor <- cor(x = pricesTrainGraph$SalePrice, y = pricesTrainGraph[0:32], use="complete.obs")
corrplot(mcor,method = 'shade',tl.cex = 1,
         col = COL2('PRGn'), diag = FALSE)
# pricesTrainGraph <- melt (pricesTrainGraph, id.vars = 'SalePrice', variable.name = 'Feature')



```

De este modo podemos ver que las variables BsmtFinSF2, LowQualFinSF, BsmtHalfBath, , GarageYrBlt, X3SsnPorch, MiscVal no tienen nigún tipo de correlación y podrían afectar de manera negativa en el modelo, de modo que se eliminarán así como la mayoría de variables cualitativas. En total se eliminarán las siguientes variables : *Id, MSSubClass, Street, Alley, LotShape, LandContour, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, Heating, Electrical, KitchenQual, FireplaceQu, GarageFinish, GarageQual, PavedDrive, PoolQC, Fence, MiscFeature, SaleType, SaleCondition, BsmtFinSF2, LowQualFinSF, BsmtHalfBath, , GarageYrBlt, X3SsnPorch, MiscVal*

#### Eliminación de variables

```{r}

# Remove columns using select()
pricesTrainDel <- pricesTrain %>% select(-c(Id, MSSubClass, Street, Alley, LotShape, LandContour, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, Heating, Electrical, KitchenQual, FireplaceQu, GarageFinish, GarageQual, PavedDrive, PoolQC, Fence, MiscFeature, SaleType, SaleCondition, BsmtFinSF2, LowQualFinSF, BsmtHalfBath, KitchenAbvGr, GarageYrBlt, EnclosedPorch, MiscVal))


## Ver df nuevo

## Volver variables chr a int
## pricesTrainDel %>%
##  mutate(
#    MSZoning = factor(MSZoning, levels = c('RM', 'RP', 'RL', 'RH', 'I', 'FV', 'C', 'A'), labels = c(0,1,2,3,4,5,6,7)), 
#    Utilities = factor(Utilities, levels = c('ELO','NoSeWa', 'NoSewr', 'AllPub'), labels = c(0,1,2,3)), 
#    HouseStyle = factor(HouseStyle, levels = c('SLvl', 'SFoyer', '2.5Unf', '2.5Fin', '2Story', '1.5Unf', '1.5Fin', '1Story'), labels = c(0,1,2,3,4,5,6,7)))
#  mutate(MSZoning = recode(MSZoning, 'RM' = 0, 'RP' = 1, 'RL' = 2, 'RH' = 3, 'I' = 4, 'FV' = 5, 'C' = 6, 'A' = 7), Utilities = recode(Utilities, 'ELO' = 0, 'NoSeWa' = 1, 'NoSewr' = 2, 'AllPub' = 3), HouseStyle = recode(HouseStyle, 'SLv1' = 0, 'SFoyer' = 1))


str(pricesTrainDel)
```

## Regresiones

```{r muestreo}
set.seed(123)
p <- 0.7
corte <- sample(nrow(pricesTrain), nrow(pricesTrain) * p)
train <- pricesTrain[corte,]
train['YearsBuilt'] = 2023 - train$YearBuilt
train['YearsRem'] = 2023 - train$YearRemodAdd

test <- pricesTrain[-corte,]

modelo1 <- lm(formula = `SalePrice`~`GrLivArea`, data = train)
summary(modelo1)
```

## VALIDACIÓN DEL MODELO

### Significancia global

$$Ho: \\beta\_{costos}=0$$

$$Ha: \\text{Alguno de los coeficientes es diferente de cero}$$

En la tabla anterior se puede observar que la prueba F produce un $valor-p = 2.2\times10^{-16}$ lo cual indica que el modelo tiene una significancia global.

### Significancia parcial

$$Ho: \\beta\_{\\text{costo}}=0$$

$$Ha: \\beta\_{\\text{costo}}\\neq 0$$

Con un $valor-p = 2.2\times10^{-16}$ podemos afirmar que el coeficiente del costo asociado a las ventas, es diferente de cero, por lo que la variable "costo", es significativa en el modelo generado.

## COEFICIENDE DE DETERMINACI?N:

El coeficiete de determinaci?n del modelo es $r^2 = 0.4877$, lo cual indica que el 48.7% de la variabilidad del fen?meno esta siendo explicado por el modelo generado.

El $r^2$ ajustado se encuentra bastante cercado al coeficiente de determinación, por lo que la colinealidad no es un problema que nos deba preocupar.

## ANÁLISIS DE RESIDUALES

### Normalidad (Prueba de lillie)

$$Ho: \text{Normalidad en los residuales}$$

$$Ha: \text{No hay normalidad en los residuales}$$

```{r}
library(nortest)
lillie.test(modelo1$residuals)
```

El test anterior nos brinda un $valor-p =2.2\times10^{-16} < 0.05$, por lo que tenemos evidencia suficiente para rechazar la hip?tesis nula, y con una significancia de 0.05, los residuales no tienen un comportamiento normal. Por lo que no se podria recomendar la utilizaci?n del modelo generado.

### VARIANZA CONSTANTE (Homocedasticidad)

Utilizaremos la prueba de Breusch Pagan.

$$Ho: \text{homocedasticidad}$$

$$ Ha: \text{no homocedasticidad}$$

```{r, message=FALSE, warning=FALSE}
library(lmtest)

bptest(modelo1)
```

Con un $valor-p= 2.2\times10^{-16}<0.05$, existe evidencia de falta de homocedasticidad, por lo que podemos suponer que la varianza de los resiudales no es constante.

## Independencia de los residuos

Utilizaremos la prueba de Durbin Watson, la cual mide la autocorrelaci?n entre los residuales.

$$Ho: \text{Los residuos estan autocorrelacionados}$$

$$Ha: \text{No existe autocorrelaci?n en los residuales}$$

```{r}
dwtest(modelo1)
```

El $valor-p=9854 >0.05$ indica que los residuales est?n autocorrelacionados, por lo que podemos afirmar que los residuales no son independientes. por lo cual no es recomendado utilizar el modelo

```{r}
t.test(modelo1$residuals)
```

$$Ho: \mu_{residuales}=0$$

$$Ha: \mu_{residuales}\neq 0$$

Con un $valor-p = 1$ no hay evidencia para rechazar la hipótesis nula, por lo que parece razonable afirmar que la media de los residuales es igual a cero.

## CONCLUSI?N GENERAL

El modelo generado es:

$\hat y = 22245.586+3.221x_1$

donde:

$$x_1 = \text{area de la casa}$$

aunque no es recomendado utilizarlo por la dependencia de los residuos y falta de normalidad

```{r}
a<-predict(modelo1,newdata=data.frame(GrLivArea=test$GrLivArea))
b<-mean(a-test$GrLivArea)
plot(test$GrLivArea,a,col="green")
par(new=TRUE)
plot(test$GrLivArea,test$SalePrice,col="blue")

test['YearsBuilt'] = 2023 - test$YearBuilt
test['YearsRem'] = 2023 - test$YearRemodAdd

```

### Regresión lineal multivariable

#### Preprocesamiento de datos

```{r multivariable}
str(train)
numericasTrain <- train[, c('MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearsBuilt', 'YearsRem', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'X1stFlrSF', 'X2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'X3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'SalePrice')]
numericasTest <- test[, c('MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearsBuilt', 'YearsRem', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'X1stFlrSF', 'X2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'X3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'SalePrice')]
```

#### Correlación de las variables

```{r correlacion}
matriz_cor = cor(numericasTrain, method = 'spearman')
corrplot(matriz_cor, type = 'upper')

newNumericasTrain <- train[, c('MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', 'LowQualFinSF', 'BsmtHalfBath', 'HalfBath', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'X3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'SalePrice')]
```

Dada la correlación entre las variables evidenciada en la gráfica, es necesario prescindir de las variables YearsBuilt, YearsRem, GrLivArea, FullBath, GarageCars, GarageArea, BsmtUnfSF, BsmtFullBath, X1stFlrSF, X2ndFlrSF, BedroomAbvGr.

#### Generando el modelo

```{r modelo}
mdLnlMtv <- lm(SalePrice~., data = newNumericasTrain)
summary(mdLnlMtv)
step(mdLnlMtv)
```

De la función anterior tenemos que el mejor modelo es el de la forma

    SalePrice ~ MSSubClass + LotArea + OverallQual + BsmtFinSF1 + 
        BsmtFinSF2 + TotalBsmtSF + LowQualFinSF + HalfBath + KitchenAbvGr + 
        TotRmsAbvGrd + Fireplaces + WoodDeckSF + OpenPorchSF + EnclosedPorch + 
        X3SsnPorch + ScreenPorch + PoolArea + MoSold

Por lo tanto. Consideremos ese modelo de ahora en adelante

#### Generando el mejor modelo

```{r mejorModelo}
mejorModelo <- lm(SalePrice ~ MSSubClass + LotArea + OverallQual + BsmtFinSF1 + 
    BsmtFinSF2 + TotalBsmtSF + LowQualFinSF + HalfBath + KitchenAbvGr + 
    TotRmsAbvGrd + Fireplaces + WoodDeckSF + OpenPorchSF + EnclosedPorch + 
    X3SsnPorch + ScreenPorch + PoolArea + MoSold, data = newNumericasTrain)
summary(mejorModelo)
```

#### Validación del modelo

##### Significancia Global

\[ H_0: \beta\_1 = \beta\_2 = ... = \beta\_n = 0 \]

\[ H_1: \text{Alguno de los coeficientes es diferente de 0} \]

Dado que \$ \text{valor-p} \< 2 \times 10\^{-16} \< 0.05 \implies H_0 \$ se rechaza, por lo cual es razonable afirmar que el modelo tiene significancia global.

##### Significancia individual

De la tabla anterior tenemos que, con un nivel de significancia de 5%, las variables BsmtFinSF2, LowQualFinSF, OpenPorchSF, X3SsnPorch, ScreenPorch, PoolArea, MoSold no poseen significancia individual. Por lo tanto, procedamos a crear un modelo sin estas variables.

##### Nuevo modelo

```{r nuevoModelo}
mdLnMtvS <- lm(SalePrice ~ MSSubClass + LotArea + OverallQual + BsmtFinSF1 + TotalBsmtSF + HalfBath + KitchenAbvGr + TotRmsAbvGrd + Fireplaces + WoodDeckSF + EnclosedPorch, data = newNumericasTrain)
summary(mdLnMtvS)
```

##### Análisis de residuales

###### Normalidad

```{r normalidad}
qqnorm(mdLnMtvS$residuals)
qqline(mdLnMtvS$residuals)
```

Es discutible el hablar de normalidad utilizando la gráfica anterior, pues en los datos del centro pareciera existir, pero los puntos de los extremos se alejan demasiado de la línea de los 45°. Por lo que se realizará una prueba de Lilliefors para determinar si existe dicha normalidad

$$ H_0: \text{Normalidad en los residuales} $$ $$ H_1: \text{No hay normalidad en los residuales} $$

```{r}
lillie.test(mdLnMtvS$residuals)
```

El test anterior nos brinda un \$ \text{valor-p} = 2.2 \times 10\^{-16} \< \alpha = 0.05 \implies H_0 \$ debe ser rechazada y, por lo tanto, no existe evidencia suficiente para afirmar que los residuales se comportan de forma normal.

###### Homocedasticidad

Utilizaremos la prueba de Breusch Pagan. $$ H_0: \text{Homocedasticidad} $$ $$ H_1: \text{No homocedasticidad} $$

```{r homocedasticidad}
bptest(mdLnMtvS)
```

El test anterior devuelve un \$ \text{valor-p} = 2.2 \times 10\^{-16} \< \alpha 0.05 \implies H_0 \$ debe ser rechazada, por lo que no existe evidencia para afirmar homocedasticidad.

###### Independencia

```{r independenciaGrafica}
plot(mdLnMtvS$fitted.values, mdLnMtvS$residuals)
```

En la gráfica se puede observar que los residuales siguen un patrón bien definido, lo cual es un claro indicador de la ausencia de independencia.

###### Independencia de los residuales

Utilizaremos la prueba de Durbin Watson, la cual mide la autocorrelación entre los residuales.

$$ H_0:  \text{Los residuales estan autocorrelacionados}$$ $$ H_1: \text{No existe autocorrelación en los residuales}$$

```{r independencia}
dwtest(mdLnMtvS)
```

El test anterior devuelve un $valor-p = 0.8921 > \alpha = 0.05 \implies H_0$ no puede ser rechazada, esto indica que los residuales están autocorrelacionados, por lo que podemos afirmar que los residuales no son independientes.

###### Valor esperado igual a 0

```{r valorEsperado}
t.test(mdLnMtvS$residuals)

```

$$ H_0: \mu_{residuales} = 0 $$ $$ H_1: \mu_{residuales} \neq 0 $$

Con un $valor-p = 1 > \alpha = 0.05 \implies H_0$ no puede ser rechazada, por lo que es posible afirmar que la media de los residuales es igual a 0

###### Conclusión

Debido a que el modelo no cumple con los supuestos, no se recomienda su uso para predecir el precio de las casas en Ames y Iowa.

##### Predicción

```{r prediccion}
prediccion <- predict(mdLnMtvS, newdata = test)
mean((prediccion - test$SalePrice)^2)
```

Podemos ver que el error medio cuadrado es de 1303358790, lo cual confirma la conclusión anterior que el modelo no es adecuado para la predicción del precio de las casas.

### Comparación de los modelos generados

Veamos que tenemos el modelo generado por una sola variable, el modelo generado por todas las variables y el mejor modelo encontrado, utilizando solo algunas de las variables. A continuación podemos ver las gráficas de los tres modelos

```{r}
pricesTest <- read.csv("test.csv")
plot(predict(modelo1, newdata = pricesTest), col="green")
par(new=TRUE)
plot(predict(mdLnlMtv, newdata = pricesTest), col="red")
par(new=TRUE)
plot(predict(mdLnMtvS, newdata = pricesTest), col="blue")
```

Dado que los modelos 2 y 3 son multivariables, es imposible graficarlos en dos dimensiones, por lo que nos guiamos más que todo por los resultados obtenidos en las pruebas. Podemos ver claramente que el modelo 1 (verde) es el peor, el que solo utiliza una variable. Esto es debido a que los supuestos no se cumplen, y los datos se ajustan en menos del $50\%$ de los datos. Por otro lado tenemos el modelo utilizando todas las variables (rojo), el cual tampoco es fectivo, prinicpalmente porque muchas variables muestran correlación entre sí, así como el mejor modelo (azul), el cual vemos que es muy similar al anterior. Ambos se ajustan a los datos reales en un $74\%$. De cualqueir manera, no se recomienda la utilización de ninguno de estos modelos para la predicción del precio de las casas
